#include "gpu_stream_processor.hpp"
#include <iostream>
#include <vector>
#include <random>

using namespace cccl_extensions;

/**
 * @brief GPU Stream Processor ä½¿ç”¨ç¤ºä¾‹
 *
 * è¿™ä¸ªç¤ºä¾‹å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨æˆ‘ä»¬åŸºäºCCCLå¼€å‘çš„GPUæ•°æ®æµå¤„ç†æ¡†æ¶
 * æ¥å®ç°é«˜æ€§èƒ½çš„å¹¶è¡Œæ•°æ®å¤„ç†ã€‚
 */

void example_basic_usage() {
    std::cout << "=== åŸºæœ¬ä½¿ç”¨ç¤ºä¾‹ ===" << std::endl;

    // 1. åˆ›å»ºå¤„ç†å™¨
    const size_t BUFFER_SIZE = 256 * 1024;  // 256Kå…ƒç´ 
    const int NUM_STREAMS = 4;

    auto processor = std::make_unique<GPUStreamProcessor<float>>(BUFFER_SIZE, NUM_STREAMS);

    // 2. è®¾ç½®å¤„ç†å‡½æ•°ï¼šç®€å•çš„æ•°å­¦å˜æ¢
    processor->set_process_function(
        ProcessFunctions::make_transform_function<float>(
            [] __device__ (float x) {
                return sinf(x) * cosf(x) + 1.0f;
            }
        )
    );

    // 3. è®¾ç½®å®Œæˆå›è°ƒ
    processor->set_completion_callback(
        [](int buffer_id, float time_ms) {
            std::cout << "  ç¼“å†²åŒº " << buffer_id << " å®Œæˆï¼Œè€—æ—¶: "
                      << time_ms << " ms" << std::endl;
        }
    );

    // 4. å‡†å¤‡æ•°æ®
    std::vector<float> data(BUFFER_SIZE * 6);  // 6ä¸ªç¼“å†²åŒºçš„æ•°æ®
    std::random_device rd;
    std::mt19937 gen(rd());
    std::uniform_real_distribution<float> dis(-3.14f, 3.14f);

    for (auto& val : data) {
        val = dis(gen);
    }

    // 5. å¤„ç†æ•°æ®æµ
    std::cout << "å¼€å§‹å¤„ç†æ•°æ®æµ..." << std::endl;
    size_t processed = processor->process_stream(data.data(), data.size());

    // 6. æŸ¥çœ‹æ€§èƒ½æŒ‡æ ‡
    auto metrics = processor->get_metrics();
    std::cout << "å¤„ç†å®Œæˆï¼" << std::endl;
    std::cout << "æ€»å¤„ç†å…ƒç´ : " << processed << std::endl;
    std::cout << "å¹³å‡ååé‡: " << metrics.get_average_throughput_mbps() << " MB/s" << std::endl;
}

void example_factory_usage() {
    std::cout << "\n=== å·¥å‚å‡½æ•°ä½¿ç”¨ç¤ºä¾‹ ===" << std::endl;

    // ä½¿ç”¨å·¥å‚å‡½æ•°åˆ›å»ºæ’åºå¤„ç†å™¨
    auto sort_processor = ProcessorFactory::create_sort_processor<int>(128 * 1024, 3);

    // å‡†å¤‡éšæœºæ•°æ®
    std::vector<int> data(128 * 1024 * 4);  // 512Kä¸ªæ•´æ•°
    std::random_device rd;
    std::mt19937 gen(rd());
    std::uniform_int_distribution<int> dis(0, 1000000);

    for (auto& val : data) {
        val = dis(gen);
    }

    std::cout << "å¼€å§‹æ’åº " << data.size() << " ä¸ªæ•´æ•°..." << std::endl;
    auto start = std::chrono::high_resolution_clock::now();

    size_t processed = sort_processor->process_stream(data.data(), data.size());

    auto end = std::chrono::high_resolution_clock::now();
    auto duration = std::chrono::duration_cast<std::chrono::milliseconds>(end - start);

    std::cout << "æ’åºå®Œæˆï¼è€—æ—¶: " << duration.count() << " ms" << std::endl;

    auto metrics = sort_processor->get_metrics();
    std::cout << "æ’åºååé‡: " << metrics.get_average_throughput_mbps() << " MB/s" << std::endl;
}

void example_custom_processing() {
    std::cout << "\n=== è‡ªå®šä¹‰å¤„ç†ç¤ºä¾‹ ===" << std::endl;

    // åˆ›å»ºå¤„ç†å™¨
    auto processor = std::make_unique<GPUStreamProcessor<double>>(64 * 1024, 2);

    // è‡ªå®šä¹‰å¤æ‚å¤„ç†å‡½æ•°ï¼šç»Ÿè®¡è®¡ç®—
    processor->set_process_function([] (double* data, size_t size, cudaStream_t stream) {
        // è®¡ç®—ç»Ÿè®¡ä¿¡æ¯ï¼šå‡å€¼å’Œæ–¹å·®
        thrust::device_vector<double> d_data(data, data + size);

        // è®¡ç®—å‡å€¼
        double sum = thrust::reduce(thrust::cuda::par.on(stream),
                                  d_data.begin(), d_data.end(), 0.0);
        double mean = sum / size;

        // è®¡ç®—æ–¹å·®
        thrust::device_vector<double> d_squared(size);
        thrust::transform(thrust::cuda::par.on(stream),
                         d_data.begin(), d_data.end(),
                         d_squared.begin(),
                         [mean] __device__ (double x) {
                             double diff = x - mean;
                             return diff * diff;
                         });

        double sum_sq = thrust::reduce(thrust::cuda::par.on(stream),
                                      d_squared.begin(), d_squared.end(), 0.0);
        double variance = sum_sq / size;

        // å°†ç»“æœå­˜å‚¨åˆ°åŸæ•°ç»„çš„å‰ä¸¤ä¸ªå…ƒç´ 
        cudaMemcpyAsync(data, &mean, sizeof(double), cudaMemcpyDeviceToDevice, stream);
        cudaMemcpyAsync(data + 1, &variance, sizeof(double), cudaMemcpyDeviceToDevice, stream);
    });

    // å‡†å¤‡æ­£æ€åˆ†å¸ƒæ•°æ®
    std::vector<double> normal_data(64 * 1024);
    std::random_device rd;
    std::mt19937 gen(rd());
    std::normal_distribution<double> ndist(100.0, 15.0);

    for (auto& val : normal_data) {
        val = ndist(gen);
    }

    std::cout << "å¼€å§‹ç»Ÿè®¡è®¡ç®—..." << std::endl;
    size_t processed = processor->process_stream(normal_data.data(), normal_data.size());

    std::cout << "ç»Ÿè®¡è®¡ç®—å®Œæˆï¼" << std::endl;
    std::cout << "å¤„ç†å…ƒç´ : " << processed << std::endl;

    // è·å–æ€§èƒ½æŒ‡æ ‡
    auto metrics = processor->get_metrics();
    std::cout << "è®¡ç®—ååé‡: " << metrics.get_average_throughput_mbps() << " MB/s" << std::endl;
}

void example_pipeline_processing() {
    std::cout << "\n=== æµæ°´çº¿å¤„ç†ç¤ºä¾‹ ===" << std::endl;

    const size_t DATA_SIZE = 1024 * 1024;  // 1Må…ƒç´ 

    // ç¬¬ä¸€é˜¶æ®µï¼šæ•°æ®ç”Ÿæˆå’Œåˆæ­¥å¤„ç†
    auto stage1 = ProcessorFactory::create_transform_processor<float>(256 * 1024, 3);
    stage1->set_process_function(
        ProcessFunctions::make_transform_function<float>(
            [] __device__ (float x) { return x * 2.0f + 1.0f; }
        )
    );

    // ç¬¬äºŒé˜¶æ®µï¼šè¿‡æ»¤å¤„ç†
    auto stage2 = std::make_unique<GPUStreamProcessor<float>>(256 * 1024, 2);
    stage2->set_process_function(
        ProcessFunctions::make_transform_function<float>(
            [] __device__ (float x) { return (x > 100.0f) ? x : 0.0f; }
        )
    );

    // å‡†å¤‡è¾“å…¥æ•°æ®
    std::vector<float> input_data(DATA_SIZE);
    std::random_device rd;
    std::mt19937 gen(rd());
    std::uniform_real_distribution<float> dis(0.0f, 100.0f);

    for (auto& val : input_data) {
        val = dis(gen);
    }

    std::cout << "å¼€å§‹æµæ°´çº¿å¤„ç†..." << std::endl;
    auto start = std::chrono::high_resolution_clock::now();

    // é˜¶æ®µ1å¤„ç†
    size_t processed1 = stage1->process_stream(input_data.data(), input_data.size());
    auto metrics1 = stage1->get_metrics();

    // é˜¶æ®µ2å¤„ç†
    size_t processed2 = stage2->process_stream(input_data.data(), input_data.size());
    auto metrics2 = stage2->get_metrics();

    auto end = std::chrono::high_resolution_clock::now();
    auto total_time = std::chrono::duration_cast<std::chrono::milliseconds>(end - start);

    std::cout << "æµæ°´çº¿å¤„ç†å®Œæˆï¼" << std::endl;
    std::cout << "æ€»è€—æ—¶: " << total_time.count() << " ms" << std::endl;
    std::cout << "é˜¶æ®µ1ååé‡: " << metrics1.get_average_throughput_mbps() << " MB/s" << std::endl;
    std::cout << "é˜¶æ®µ2ååé‡: " << metrics2.get_average_throughput_mbps() << " MB/s" << std::endl;
}

int main() {
    std::cout << "GPU Stream Processor ä½¿ç”¨ç¤ºä¾‹" << std::endl;
    std::cout << "===============================" << std::endl;

    try {
        // åŸºæœ¬ä½¿ç”¨
        example_basic_usage();

        // å·¥å‚å‡½æ•°ä½¿ç”¨
        example_factory_usage();

        // è‡ªå®šä¹‰å¤„ç†
        example_custom_processing();

        // æµæ°´çº¿å¤„ç†
        example_pipeline_processing();

        std::cout << "\nğŸ‰ æ‰€æœ‰ç¤ºä¾‹æ‰§è¡ŒæˆåŠŸï¼" << std::endl;
        std::cout << "\nè¿™ä¸ªGPUæ•°æ®æµå¤„ç†æ¡†æ¶å±•ç¤ºäº†å¦‚ä½•ï¼š" << std::endl;
        std::cout << "â€¢ åˆ©ç”¨CCCLç»„ä»¶æ„å»ºé«˜æ€§èƒ½å¤„ç†ç®¡é“" << std::endl;
        std::cout << "â€¢ å®ç°å¼‚æ­¥å¹¶è¡Œå¤„ç†" << std::endl;
        std::cout << "â€¢ æä¾›çµæ´»çš„è‡ªå®šä¹‰å¤„ç†å‡½æ•°" << std::endl;
        std::cout << "â€¢ æ”¯æŒæµå¼æ•°æ®å¤„ç†" << std::endl;
        std::cout << "â€¢ å®ç°æ€§èƒ½ç›‘æ§å’Œè‡ªåŠ¨è°ƒä¼˜" << std::endl;

    } catch (const std::exception& e) {
        std::cerr << "âŒ ç¤ºä¾‹æ‰§è¡Œå¤±è´¥: " << e.what() << std::endl;
        return 1;
    }

    return 0;
}