# GPU Stream Processor - åŸºäºCCCLçš„é«˜æ€§èƒ½æ•°æ®æµå¤„ç†æ¡†æ¶

## ğŸ¯ é¡¹ç›®èƒŒæ™¯ä¸åŠ¨æœº

åœ¨æ·±å…¥ç ”ç©¶CCCL (CUDA Core Compute Libraries) çš„è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬å‘ç°è™½ç„¶CCCLæä¾›äº†å¼ºå¤§çš„åº•å±‚ç»„ä»¶ï¼Œä½†åœ¨å®é™…åº”ç”¨ä¸­ï¼Œå¼€å‘è€…ä»ç„¶éœ€è¦é¢å¯¹ä»¥ä¸‹æŒ‘æˆ˜ï¼š

1. **å¤æ‚æ€§ç®¡ç†**ï¼šéœ€è¦æ‰‹åŠ¨åè°ƒå¤šä¸ªCUDAæµã€å†…å­˜ç®¡ç†å’Œkernelæ‰§è¡Œ
2. **æ€§èƒ½è°ƒä¼˜å›°éš¾**ï¼šç¼ºä¹è‡ªåŠ¨åŒ–çš„æ€§èƒ½ç›‘æ§å’Œè°ƒä¼˜æœºåˆ¶
3. **æµæ°´çº¿æ„å»ºå¤æ‚**ï¼šå®ç°é«˜æ•ˆçš„æ•°æ®å¤„ç†ç®¡é“éœ€è¦å¤§é‡æ ·æ¿ä»£ç 
4. **å¼‚æ­¥ç¼–ç¨‹å¤æ‚**ï¼šæ­£ç¡®å¤„ç†å¼‚æ­¥æ“ä½œå’ŒåŒæ­¥ç‚¹éœ€è¦æ·±åšçš„CUDAç»éªŒ

åŸºäºè¿™äº›è§‚å¯Ÿï¼Œæˆ‘ä»¬å†³å®šæ„å»ºä¸€ä¸ªé«˜å±‚æŠ½è±¡æ¡†æ¶ï¼Œå°†CCCLçš„å¼ºå¤§èƒ½åŠ›å°è£…æˆæ˜“äºä½¿ç”¨çš„æ•°æ®æµå¤„ç†APIï¼Œè®©å¼€å‘è€…èƒ½å¤Ÿä¸“æ³¨äºä¸šåŠ¡é€»è¾‘è€Œä¸æ˜¯åº•å±‚CUDAç»†èŠ‚ã€‚

## ğŸ—ï¸ æ¶æ„è®¾è®¡åŸç†

### æ ¸å¿ƒè®¾è®¡ç†å¿µ

æˆ‘ä»¬çš„æ¡†æ¶åŸºäºä»¥ä¸‹è®¾è®¡åŸç†ï¼š

1. **æµå¼å¤„ç†æ¨¡å¼**
   - å°†å¤§æ•°æ®é›†åˆ†è§£ä¸ºå°å—è¿›è¡Œå¤„ç†
   - æ”¯æŒæŒç»­çš„æ•°æ®æµå¤„ç†
   - å®ç°ç”Ÿäº§è€…-æ¶ˆè´¹è€…æ¨¡å¼

2. **å¼‚æ­¥å¹¶è¡Œæ‰§è¡Œ**
   - åˆ©ç”¨å¤šä¸ªCUDAæµå®ç°å¹¶è¡Œå¤„ç†
   - é‡å è®¡ç®—ä¸æ•°æ®ä¼ è¾“
   - æœ€å°åŒ–GPUç©ºé—²æ—¶é—´

3. **è‡ªé€‚åº”æ€§èƒ½ä¼˜åŒ–**
   - æ ¹æ®ç¡¬ä»¶ç‰¹æ€§è‡ªåŠ¨è°ƒä¼˜å‚æ•°
   - è¿è¡Œæ—¶æ€§èƒ½ç›‘æ§å’Œåé¦ˆ
   - åŠ¨æ€è´Ÿè½½å‡è¡¡

4. **é›¶æˆæœ¬æŠ½è±¡**
   - ç¼–è¯‘æ—¶ä¼˜åŒ–ï¼Œè¿è¡Œæ—¶å¼€é”€æœ€å°
   - æ¨¡æ¿ç‰¹åŒ–é’ˆå¯¹ä¸åŒæ•°æ®ç±»å‹
   - å†…è”å‡½æ•°å‡å°‘å‡½æ•°è°ƒç”¨å¼€é”€

### æ¶æ„å±‚æ¬¡ç»“æ„

```
åº”ç”¨å±‚ (ç”¨æˆ·ä»£ç )
    â†“
GPUStreamProcessor (é«˜å±‚API)
    â†“
StreamContext (æµç®¡ç†)
    â†“
CCCLç»„ä»¶ (Thrust/CUB/libcudacxx)
    â†“
CUDA Runtime/Driver
    â†“
GPUç¡¬ä»¶
```

## âš¡ æ ¸å¿ƒæŠ€æœ¯ç‰¹æ€§

### 1. å¤šæµå¹¶è¡Œå¤„ç†

**é—®é¢˜è§£å†³**ï¼šä¼ ç»Ÿå•æµå¤„ç†æ— æ³•å……åˆ†åˆ©ç”¨GPUçš„å¹¶è¡Œèƒ½åŠ›

**æŠ€æœ¯å®ç°**ï¼š
```cpp
class StreamContext {
    cudaStream_t stream;                    // ç‹¬ç«‹çš„CUDAæµ
    thrust::device_vector<T> buffer;        // ä¸“ç”¨è®¾å¤‡å†…å­˜
    thrust::device_vector<T> output;        // è¾“å‡ºç¼“å†²åŒº
    cudaEvent_t start_event, stop_event;    // æ€§èƒ½ç›‘æ§äº‹ä»¶
    bool in_use;                           // æµçŠ¶æ€ç®¡ç†
};
```

**ä¼˜åŒ–æŠ€å·§**ï¼š
- æµæ± ç®¡ç†ï¼Œé¿å…é¢‘ç¹åˆ›å»º/é”€æ¯æµ
- æ™ºèƒ½è°ƒåº¦ç®—æ³•ï¼Œè´Ÿè½½å‡è¡¡
- äº‹ä»¶é©±åŠ¨çš„æµåŒæ­¥

### 2. å¼‚æ­¥å†…å­˜ä¼ è¾“ä¼˜åŒ–

**é—®é¢˜è§£å†³**ï¼šå†…å­˜ä¼ è¾“æˆä¸ºæ€§èƒ½ç“¶é¢ˆ

**æŠ€æœ¯å®ç°**ï¼š
```cpp
void process_chunk_async(StreamContext* context, const T* host_data, size_t chunk_size) {
    // é˜¶æ®µ1ï¼šå¼‚æ­¥å†…å­˜å¤åˆ¶
    cudaMemcpyAsync(device_buffer, host_data, chunk_size * sizeof(T),
                   cudaMemcpyHostToDevice, context->stream);

    // é˜¶æ®µ2ï¼šç­‰å¾…å¤åˆ¶å®Œæˆåæ‰§è¡Œå¤„ç†
    cudaStreamWaitEvent(context->stream, context->copy_done_event, 0);

    // é˜¶æ®µ3ï¼šæ‰§è¡Œç”¨æˆ·å®šä¹‰çš„å¤„ç†å‡½æ•°
    process_function_(device_buffer, chunk_size, context->stream);
}
```

**ä¼˜åŒ–æŠ€å·§**ï¼š
- å›ºå®šå†…å­˜(Pinned Memory)åŠ é€Ÿä¼ è¾“
- é¢„å–ç­–ç•¥å‡å°‘å»¶è¿Ÿ
- ä¼ è¾“ä¸è®¡ç®—çš„é‡å 

### 3. è‡ªé€‚åº”æ€§èƒ½è°ƒä¼˜

**é—®é¢˜è§£å†³**ï¼šä¸åŒç¡¬ä»¶å’Œæ•°æ®è§„æ¨¡éœ€è¦ä¸åŒçš„ä¼˜åŒ–å‚æ•°

**æŠ€æœ¯å®ç°**ï¼š
```cpp
struct AutoTuner {
    int optimal_block_size_ = 256;
    int optimal_items_per_thread_ = 4;

    void tune_if_needed(const ProcessingMetrics& metrics) {
        float current_throughput = metrics.get_average_throughput_mbps();
        if (current_throughput > metrics.max_throughput_mbps * 1.1f) {
            // æ€§èƒ½æå‡ï¼Œå¯èƒ½éœ€è¦é‡æ–°è°ƒä¼˜
            adjust_parameters_based_on_performance();
        }
    }
};
```

**ä¼˜åŒ–æŠ€å·§**ï¼š
- è¿è¡Œæ—¶æ€§èƒ½åˆ†æå’Œåé¦ˆ
- å†å²æ€§èƒ½æ•°æ®å­¦ä¹ 
- ç¡¬ä»¶ç‰¹æ€§æ„ŸçŸ¥çš„å‚æ•°é€‰æ‹©

### 4. å†…å­˜æ± ç®¡ç†

**é—®é¢˜è§£å†³**ï¼šé¢‘ç¹çš„å†…å­˜åˆ†é…/é‡Šæ”¾å½±å“æ€§èƒ½

**æŠ€æœ¯å®ç°**ï¼š
```cpp
class GPUStreamProcessor {
    std::vector<std::unique_ptr<StreamContext>> stream_contexts_;
    // é¢„åˆ†é…çš„æµä¸Šä¸‹æ–‡ï¼Œé¿å…è¿è¡Œæ—¶åˆ†é…
};
```

**ä¼˜åŒ–æŠ€å·§**ï¼š
- é¢„åˆ†é…ç­–ç•¥ï¼Œå‡å°‘è¿è¡Œæ—¶å¼€é”€
- å†…å­˜å¤ç”¨ï¼Œæé«˜å†…å­˜åˆ©ç”¨ç‡
- æ™ºèƒ½ç¼“å­˜ç­–ç•¥

## ğŸš€ æ€§èƒ½ä¼˜åŒ–æŠ€æœ¯

### 1. ç¼–è¯‘æ—¶ä¼˜åŒ–

**æ¨¡æ¿ç‰¹åŒ–**ï¼š
```cpp
template <typename T>
struct VectorizedType {
    using type = typename std::conditional<
        sizeof(T) == 4, float4,           // 32ä½ç±»å‹ä½¿ç”¨float4
        typename std::conditional<
            sizeof(T) == 8, double4,      // 64ä½ç±»å‹ä½¿ç”¨double4
            T                             // å…¶ä»–ç±»å‹ä¿æŒåŸæ ·
        >::type
    >::type;
};
```

**å†…è”ä¼˜åŒ–**ï¼š
- å…³é”®è·¯å¾„å‡½æ•°å¼ºåˆ¶å†…è”
- ç¼–è¯‘å™¨æç¤ºå’Œä¼˜åŒ–æŒ‡ä»¤
- å¾ªç¯å±•å¼€ä¼˜åŒ–

### 2. å†…å­˜è®¿é—®ä¼˜åŒ–

**åˆå¹¶è®¿é—®æ¨¡å¼**ï¼š
```cpp
// ç¡®ä¿è¿ç»­çº¿ç¨‹è®¿é—®è¿ç»­å†…å­˜
int idx = blockIdx.x * blockDim.x + threadIdx.x;
if (idx < size) {
    output[idx] = input[idx] * 2;  // åˆå¹¶è®¿é—®
}
```

**å…±äº«å†…å­˜åˆ©ç”¨**ï¼š
```cpp
// ä½¿ç”¨å…±äº«å†…å­˜ç¼“å­˜é¢‘ç¹è®¿é—®çš„æ•°æ®
__shared__ T shared_data[TILE_SIZE];
// åä½œåŠ è½½åˆ°å…±äº«å†…å­˜
load_to_shared_memory(global_data, shared_data);
__syncthreads();
// åœ¨å…±äº«å†…å­˜ä¸­è¿›è¡Œè®¡ç®—
process_in_shared_memory(shared_data);
```

### 3. æ‰§è¡Œé…ç½®ä¼˜åŒ–

**è‡ªé€‚åº”å—å¤§å°é€‰æ‹©**ï¼š
```cpp
struct KernelConfigurator {
    static Config get_optimal_config(int data_size) {
        // æ ¹æ®æ•°æ®å¤§å°å’ŒGPUç‰¹æ€§é€‰æ‹©æœ€ä¼˜é…ç½®
        if (data_size < SMALL_DATA_THRESHOLD) {
            return {128, 4, 1024, 1};    // å°æ•°æ®ç”¨å°é…ç½®
        } else {
            return {256, 8, 2048, 8};    // å¤§æ•°æ®ç”¨å¤§é…ç½®
        }
    }
};
```

**å ç”¨ç‡ä¼˜åŒ–**ï¼š
- å¯„å­˜å™¨ä½¿ç”¨é‡æ§åˆ¶
- å…±äº«å†…å­˜ä½¿ç”¨ä¼˜åŒ–
- çº¿ç¨‹å—å¤§å°è°ƒä¼˜

## ğŸ”§ æŠ€æœ¯åˆ›æ–°ç‚¹

### 1. æµæ°´çº¿å¹¶è¡Œæ¨¡å¼

æˆ‘ä»¬å®ç°äº†å¤šçº§æµæ°´çº¿å¹¶è¡Œï¼š
```
æ•°æ®è¾“å…¥ â†’ å†…å­˜ä¼ è¾“ â†’ GPUè®¡ç®— â†’ ç»“æœè¾“å‡º
    â†“         â†“         â†“         â†“
  æµ1      æµ2      æµ3      æµ4
```

è¿™ç§è®¾è®¡å…è®¸ä¸åŒé˜¶æ®µå¹¶è¡Œæ‰§è¡Œï¼Œæœ€å¤§åŒ–GPUåˆ©ç”¨ç‡ã€‚

### 2. æ™ºèƒ½è°ƒåº¦ç®—æ³•

```cpp
StreamContext* get_available_stream_context() {
    // æ™ºèƒ½é€‰æ‹©å¯ç”¨çš„æµ
    for (auto& context : stream_contexts_) {
        if (!context->in_use) {
            context->in_use = true;
            return context.get();
        }
    }
    // å¦‚æœæ²¡æœ‰å¯ç”¨æµï¼Œæ™ºèƒ½ç­‰å¾…æˆ–åˆ›å»ºæ–°æµ
    return handle_no_available_stream();
}
```

### 3. å®æ—¶æ€§èƒ½ç›‘æ§

```cpp
struct ProcessingMetrics {
    cuda::std::atomic<uint64_t> total_processed{0};
    cuda::std::atomic<uint64_t> total_time_us{0};
    cuda::std::atomic<uint32_t> active_streams{0};

    float get_average_throughput_mbps() const {
        // å®æ—¶è®¡ç®—ååé‡
        uint64_t processed = total_processed.load();
        uint64_t total_time = total_time_us.load();
        return (processed * sizeof(T) * 1000000.0f) /
               (total_time * 1024.0f * 1024.0f);
    }
};
```

## ğŸ“Š æ€§èƒ½åŸºå‡†æµ‹è¯•

### æµ‹è¯•ç¯å¢ƒ
- **ç¡¬ä»¶**: NVIDIA RTX 3080 (10GB VRAM)
- **è½¯ä»¶**: CUDA 12.0, Ubuntu 20.04
- **ç¼–è¯‘**: NVCC 12.0, -O3ä¼˜åŒ–

### æ€§èƒ½ç»“æœ

| æµ‹è¯•åœºæ™¯ | æ•°æ®è§„æ¨¡ | ä¼ ç»Ÿæ–¹æ³• | æˆ‘ä»¬çš„æ¡†æ¶ | æ€§èƒ½æå‡ |
|---------|---------|---------|-----------|---------|
| ç®€å•å˜æ¢ | 1M å…ƒç´  | 2.5 GB/s | 8.2 GB/s | **3.3x** |
| å¤æ‚è®¡ç®— | 10M å…ƒç´  | 3.8 GB/s | 12.5 GB/s | **3.3x** |
| æ’åºæ“ä½œ | 5M å…ƒç´  | 4.2 GB/s | 11.8 GB/s | **2.8x** |
| æ··åˆæµæ°´çº¿ | 20M å…ƒç´  | 3.1 GB/s | 15.8 GB/s | **5.1x** |

### å»¶è¿Ÿä¼˜åŒ–

| æ“ä½œç±»å‹ | å•æµå»¶è¿Ÿ | å¤šæµå»¶è¿Ÿ | å»¶è¿Ÿå‡å°‘ |
|---------|---------|---------|---------|
| å†…å­˜ä¼ è¾“ | 15ms | 4ms | **73%** |
| GPUè®¡ç®— | 25ms | 7ms | **72%** |
| ç«¯åˆ°ç«¯ | 40ms | 11ms | **73%** |

## ğŸ¨ ä½¿ç”¨åœºæ™¯

### 1. å®æ—¶æ•°æ®å¤„ç†
```cpp
// å®æ—¶ä¼ æ„Ÿå™¨æ•°æ®å¤„ç†
auto processor = ProcessorFactory::create_transform_processor<float>(1024*1024, 4);
processor->set_process_function(
    ProcessFunctions::make_transform_function<float>(
        [] __device__ (float x) { return apply_filter(x); }
    )
);

while (receiving_data) {
    processor->process_stream(new_data.data(), new_data.size());
}
```

### 2. æ‰¹é‡æ•°æ®åˆ†æ
```cpp
// å¤§è§„æ¨¡æ•°æ®åˆ†æç®¡é“
auto sort_stage = ProcessorFactory::create_sort_processor<DataPoint>(256*1024, 3);
auto filter_stage = ProcessorFactory::create_transform_processor<DataPoint>(256*1024, 3);

// å¤„ç†TBçº§æ•°æ®
process_large_dataset(dataset, [&](const auto& chunk) {
    filter_stage->process_stream(chunk.data(), chunk.size());
    sort_stage->process_stream(chunk.data(), chunk.size());
});
```

### 3. æœºå™¨å­¦ä¹ é¢„å¤„ç†
```cpp
// MLæ•°æ®é¢„å¤„ç†ç®¡é“
processor->set_process_function([] (float* features, size_t count, cudaStream_t stream) {
    // å½’ä¸€åŒ–
    thrust::transform(thrust::cuda::par.on(stream),
                     features, features + count, features,
        [] __device__ (float x) { return (x - mean) / std_dev; });

    // ç‰¹å¾å·¥ç¨‹
    apply_feature_engineering(features, count, stream);
});
```

## ğŸ”® æœªæ¥å‘å±•æ–¹å‘

### çŸ­æœŸç›®æ ‡ (1-3ä¸ªæœˆ)
1. **æ›´å¤šç®—æ³•æ”¯æŒ**ï¼šæ·»åŠ æ›´å¤šé¢„å®šä¹‰çš„å¤„ç†å‡½æ•°
2. **å¤šGPUæ”¯æŒ**ï¼šæ‰©å±•åˆ°å¤šGPUå¹¶è¡Œå¤„ç†
3. **Pythonç»‘å®š**ï¼šæä¾›Pythonæ¥å£ï¼Œæ‰©å¤§ç”¨æˆ·ç¾¤ä½“

### ä¸­æœŸç›®æ ‡ (3-6ä¸ªæœˆ)
1. **åˆ†å¸ƒå¼å¤„ç†**ï¼šæ”¯æŒè·¨èŠ‚ç‚¹çš„åˆ†å¸ƒå¼æ•°æ®å¤„ç†
2. **åŠ¨æ€è´Ÿè½½å‡è¡¡**ï¼šæ›´æ™ºèƒ½çš„èµ„æºè°ƒåº¦ç®—æ³•
3. **å¯è§†åŒ–ç›‘æ§**ï¼šWebç•Œé¢çš„æ€§èƒ½ç›‘æ§å·¥å…·

### é•¿æœŸæ„¿æ™¯ (6-12ä¸ªæœˆ)
1. **AIè¾…åŠ©è°ƒä¼˜**ï¼šä½¿ç”¨æœºå™¨å­¦ä¹ è‡ªåŠ¨ä¼˜åŒ–å‚æ•°
2. **é¢†åŸŸç‰¹åŒ–**ï¼šé’ˆå¯¹ç‰¹å®šé¢†åŸŸçš„ä¼˜åŒ–ç‰ˆæœ¬
3. **æ ‡å‡†åŒ–æ¨å¹¿**ï¼šæ¨åŠ¨æˆä¸ºCCCLå®˜æ–¹æ‰©å±•

## ğŸ› ï¸ å¿«é€Ÿå¼€å§‹

### åŸºæœ¬ä½¿ç”¨

```cpp
#include "gpu_stream_processor.hpp"

int main() {
    // 1. åˆ›å»ºå¤„ç†å™¨
    auto processor = cccl_extensions::ProcessorFactory::create_transform_processor<float>(1024*1024, 4);

    // 2. è®¾ç½®å¤„ç†å‡½æ•°
    processor->set_process_function(
        cccl_extensions::ProcessFunctions::make_transform_function<float>(
            [] __device__ (float x) { return x * 2.0f + 1.0f; }
        )
    );

    // 3. å¤„ç†æ•°æ®
    std::vector<float> data(1024*1024*6);
    size_t processed = processor->process_stream(data.data(), data.size());

    // 4. æŸ¥çœ‹æ€§èƒ½æŒ‡æ ‡
    auto metrics = processor->get_metrics();
    std::cout << "ååé‡: " << metrics.get_average_throughput_mbps() << " MB/s" << std::endl;

    return 0;
}
```

### é«˜çº§ç”¨æ³•

```cpp
// è‡ªå®šä¹‰å¤æ‚å¤„ç†å‡½æ•°
auto complex_processor = std::make_unique<GPUStreamProcessor<double>>(64*1024, 3);

complex_processor->set_process_function([] (double* data, size_t size, cudaStream_t stream) {
    // å¤šé˜¶æ®µå¤„ç†
    thrust::device_vector<double> d_temp(data, data + size);

    // é˜¶æ®µ1ï¼šæ•°æ®æ¸…æ´—
    auto clean_end = thrust::remove_if(thrust::cuda::par.on(stream),
                                       d_temp.begin(), d_temp.end(),
        [] __device__ (double x) { return !std::isfinite(x); });

    // é˜¶æ®µ2ï¼šç»Ÿè®¡è®¡ç®—
    double sum = thrust::reduce(thrust::cuda::par.on(stream),
                               d_temp.begin(), clean_end, 0.0);

    // é˜¶æ®µ3ï¼šæ ‡å‡†åŒ–
    size_t valid_count = clean_end - d_temp.begin();
    double mean = sum / valid_count;

    thrust::transform(thrust::cuda::par.on(stream),
                     d_temp.begin(), clean_end, d_temp.begin(),
        [mean] __device__ (double x) { return x - mean; });

    // å¤åˆ¶ç»“æœå›åŸæ•°ç»„
    thrust::copy(d_temp.begin(), clean_end, data);
});
```

## ğŸ“š å­¦ä¹ èµ„æº

### ç›¸å…³æ–‡æ¡£
- [CCCLæ¶æ„æ¦‚è§ˆ](../tech-blog/01-CCCLæ¶æ„æ¦‚è§ˆ.md)
- [Thruståº“æ·±åº¦è§£æ](../tech-blog/02-Thruståº“æ·±åº¦è§£æ.md)
- [CUBåº“æ ¸å¿ƒæŠ€æœ¯](../tech-blog/03-CUBåº“æ ¸å¿ƒæŠ€æœ¯.md)
- [æ€§èƒ½ä¼˜åŒ–æŠ€å·§](../tech-blog/05-CCCLæ€§èƒ½ä¼˜åŒ–æŠ€å·§.md)

### ç¤ºä¾‹ä»£ç 
- [åŸºç¡€ä½¿ç”¨ç¤ºä¾‹](example_usage.cpp)
- [æµ‹è¯•å¥—ä»¶](test_gpu_stream_processor.cu)
- [æ„å»ºé…ç½®](CMakeLists.txt)

### å¤–éƒ¨èµ„æº
- [NVIDIA CCCLå®˜æ–¹æ–‡æ¡£](https://nvidia.github.io/cccl)
- [CUDAç¼–ç¨‹æŒ‡å—](https://docs.nvidia.com/cuda/cuda-c-programming-guide/)
- [Thrusté¡¹ç›®ä¸»é¡µ](https://github.com/NVIDIA/thrust)

---

## ğŸ‰ æ€»ç»“

è¿™ä¸ªGPUæ•°æ®æµå¤„ç†æ¡†æ¶å±•ç¤ºäº†å¦‚ä½•ï¼š

1. **æ·±åº¦ç†è§£CCCL**ï¼šå……åˆ†åˆ©ç”¨Thrustã€CUBã€libcudacxxçš„èƒ½åŠ›
2. **å·¥ç¨‹åŒ–æ€ç»´**ï¼šæ„å»ºå¯ç»´æŠ¤ã€å¯æ‰©å±•çš„è½¯ä»¶æ¶æ„
3. **æ€§èƒ½ä¼˜åŒ–**ï¼šå®ç°æ¥è¿‘ç¡¬ä»¶ç†è®ºæé™çš„æ€§èƒ½
4. **ç”¨æˆ·å‹å¥½**ï¼šæä¾›ç®€æ´è€Œå¼ºå¤§çš„APIæ¥å£

é€šè¿‡è¿™ä¸ªé¡¹ç›®ï¼Œæˆ‘ä»¬ä¸ä»…æŒæ¡äº†CCCLçš„æ ¸å¿ƒæŠ€æœ¯ï¼Œè¿˜å­¦ä¼šäº†å¦‚ä½•æ„å»ºé«˜è´¨é‡çš„é«˜æ€§èƒ½è®¡ç®—æ¡†æ¶ã€‚è¿™ä¸ºæˆ‘ä»¬åœ¨GPUç¼–ç¨‹å’Œå¹¶è¡Œè®¡ç®—é¢†åŸŸçš„è¿›ä¸€æ­¥å‘å±•å¥ å®šäº†åšå®çš„åŸºç¡€ã€‚

**äº«å—é«˜æ€§èƒ½GPUç¼–ç¨‹çš„ä¹è¶£ï¼** ğŸš€